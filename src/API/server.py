from flask import Flask, request, jsonify
from flask_cors import CORS
import pandas as pd
import mysql.connector
from mysql.connector import Error as MySQLError
import os
import openpyxl
import bcrypt
import re
from typing import Optional, Any

app = Flask(__name__)
CORS(app)

# Configuration
UPLOAD_FOLDER = './uploads'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER

# Database Configuration
DB_CONFIG = {
    'host': 'localhost',
    'user': 'root',
    'password': '#Bb108935',
    'database': 'salary_db'
}

# Column mappings
COLUMN_MAP = {
    'cid': 'cid', 
    '‡πÄ‡∏•‡∏Ç‡∏ö‡∏±‡∏ï‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô': 'cid',
    '‡∏ä‡∏∑‡πà‡∏≠': 'name', 
    '‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ç‡∏ä‡∏µ': 'bank_account',
    '‡πÄ‡∏î‡∏∑‡∏≠‡∏ô': 'month', 
    '‡∏õ‡∏µ': 'year',
    '‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô': 'salary',
    '‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏™‡∏∏‡∏ó‡∏ò‡∏¥': 'salary_deductions',
    '‡∏£‡∏ß‡∏°‡∏£‡∏±‡∏ö': 'total_income',
    '‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏£‡∏≠‡∏á‡∏ä‡∏µ‡∏û': 'cola_allowance',
    '‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏£‡∏≠‡∏á‡∏ä‡∏µ‡∏û(‡∏ï‡∏Å‡πÄ‡∏ö‡∏¥‡∏Å)': 'retroactive_cola_allowance',
    '‡∏á/‡∏î(‡∏ï‡∏Å‡πÄ‡∏ö‡∏¥‡∏Å)': 'retroactive_salary_emp',
    '‡∏á/‡∏î ‡∏ï‡∏Å‡πÄ‡∏ö‡∏¥‡∏Å': 'retroactive_salary_emp',
    '‡∏û‡∏ï‡∏™.': 'special_public_health_allowance',
    '‡∏õ‡∏à‡∏ï.': 'position_allowance',
    '‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô': 'monthly_allowance',
    'P4P': 'pay_for_performance',
    '‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î-19': 'covid_risk_pay',
    '‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î-19': 'covid_risk_pay',
    '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏†‡∏±‡∏¢‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î': 'covid_exposure',
    '‡πÄ‡∏á‡∏¥‡∏ô‡∏Å‡∏π‡πâ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏¥‡∏Å‡∏≤‡∏£': 'welfare_loan_received',
    '‡πÇ‡∏≠‡∏ó‡∏µ': 'overtime_pay',
    '‡∏ö‡πà‡∏≤‡∏¢-‡∏î‡∏∂‡∏Å': 'evening_night_shift_pay',
    'OT/OPD': 'ot_outpatient_dept',
    'OT/‡∏û‡∏ö.': 'ot_professional',
    'OT/‡∏ú‡∏ä.': 'ot_assistant',
    '‡∏ö-‡∏î/‡∏û‡∏ö.': 'shift_professional',
    '‡∏ö-‡∏î/‡∏ú‡∏ä.': 'shift_assistant',
    '‡∏≠‡∏∑‡πà‡∏ô‡πÜ': 'other_income',
    '‡∏£‡∏ß‡∏°‡∏à‡πà‡∏≤‡∏¢': 'total_expense',
    '‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠': 'net_balance',
    '‡∏´‡∏±‡∏Å‡∏ß‡∏±‡∏ô‡∏•‡∏≤': 'leave_day_deduction',
    '‡∏†‡∏≤‡∏©‡∏µ': 'tax_deduction',
    '‡∏†‡∏≤‡∏©‡∏µ ‡∏ï‡∏Å‡πÄ‡∏ö‡∏¥‡∏Å': 'retroactive_tax_deduction',
    '‡∏Å‡∏ö‡∏Ç.': 'gpf_contribution',
    '‡∏Å‡∏ö‡∏Ç.‡∏ï‡∏Å‡πÄ‡∏ö‡∏¥‡∏Å': 'retroactive_gpf_deduction',
    '‡∏Å‡∏ö‡∏Ç.‡πÄ‡∏û‡∏¥‡πà‡∏°': 'gpf_extra_contribution',
    '‡∏õ‡∏Å‡∏™‡∏Ñ.': 'social_security_deduction_gov',
    '‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏™‡∏±‡∏á‡∏Ñ‡∏°': 'social_security_deduction_emp',
    '‡∏Å‡∏≠‡∏á‡∏ó‡∏∏‡∏ô ‡∏û‡∏Å‡∏™.': 'phks_provident_fund',
    '‡∏å‡∏Å‡∏™.': 'funeral_welfare_deduction',
    '‡∏™‡∏≠.‡∏Å‡∏£‡∏°': 'coop_deduction_dept',
    '‡∏™‡∏≠.‡∏™‡∏™‡∏à.‡πÄ‡∏•‡∏¢': 'coop_deduction_phso',
    '‡∏™‡∏™‡∏à.': 'prov_health_office',
    '‡∏Å‡∏¢‡∏®.': 'student_loan_deduction_emp',
    '‡∏Å‡∏¢‡∏®': 'student_loan_deduction_emp',
    '‡∏Ñ‡πà‡∏≤‡∏ô‡πâ‡∏≥': 'water_bill_deduction',
    '‡∏Ñ‡πà‡∏≤‡πÑ‡∏ü': 'electricity_bill_deduction',
    'net': 'internet_deduction_emp',
    '‡∏Ñ‡πà‡∏≤Net': 'internet_deduction_emp',
    'AIA': 'aia_insurance_deduction_emp',
    '‡∏Ñ‡πà‡∏≤AIA': 'aia_insurance_deduction_emp',
    '‡∏≠‡∏≠‡∏°‡∏™‡∏¥‡∏ô': 'gsb_loan_deduction_emp',
    '‡∏≠‡∏≠‡∏°‡∏™‡∏¥‡∏ô‡∏ô‡∏≤‡∏≠‡∏≤‡∏ô': 'gsb_loan_naan',
    '‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏≠‡∏≠‡∏°‡∏™‡∏¥‡∏ô‡πÄ‡∏•‡∏¢': 'gsb_loan_loei',
    '‡∏ò‡∏≠‡∏™': 'ghb_loan_deduction',
    '‡∏Å‡∏£‡∏∏‡∏á‡πÑ‡∏ó‡∏¢': 'ktb_loan_deduction_emp',
    '‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏Å‡∏£‡∏∏‡∏á‡πÑ‡∏ó‡∏¢': 'ktb_loan_deduction_emp',
    '‡πÄ‡∏á‡∏¥‡∏ô‡∏Å‡∏π‡πâ ‡∏£‡∏û.': 'hospital_loan_deduction',
    '‡πÄ‡∏á‡∏¥‡∏ô‡∏Å‡∏π‡πâ ‡∏£‡∏û/‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏á‡∏≤‡∏ô': 'hospital_loan_employment',    
    '‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏ö‡∏∏‡∏ï‡∏£': 'child_education_deduction',
    '‡∏Ñ‡πà‡∏≤‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•': 'medical_expense_deduction',
    '‡πÑ‡∏°‡πà‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏ß‡∏ä': 'no_private_practice_deduction',
}

NUMERIC_COLUMNS = {
    'salary', 'salary_deductions', 'total_income', 'cola_allowance',
    'retroactive_cola_allowance', 'retroactive_salary_emp', 'special_public_health_allowance',
    'position_allowance', 'monthly_allowance', 'pay_for_performance', 'covid_risk_pay',
    'welfare_loan_received', 'overtime_pay', 'evening_night_shift_pay', 'ot_outpatient_dept',
    'ot_professional', 'ot_assistant', 'shift_professional', 'shift_assistant', 'other_income',
    'total_expense', 'net_balance', 'leave_day_deduction', 'tax_deduction',
    'retroactive_tax_deduction', 'gpf_contribution', 'retroactive_gpf_deduction',
    'gpf_extra_contribution', 'social_security_deduction_gov', 'social_security_deduction_emp',
    'phks_provident_fund', 'funeral_welfare_deduction', 'coop_deduction_dept',
    'coop_deduction_phso', 'student_loan_deduction_emp', 'water_bill_deduction',
    'electricity_bill_deduction', 'internet_deduction_emp', 'aia_insurance_deduction_emp',
    'gsb_loan_deduction_emp', 'gsb_loan_naan', 'gsb_loan_loei', 'ghb_loan_deduction',
    'ktb_loan_deduction_emp', 'hospital_loan_deduction','hospital loan_employment', 'child_education_deduction',
    'medical_expense_deduction', 'no_private_practice_deduction'
}

MONTH_MAP = {
    '‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°': 1, '‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå': 2, '‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°': 3, '‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô': 4,
    '‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°': 5, '‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô': 6, '‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°': 7, '‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°': 8,
    '‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô': 9, '‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°': 10, '‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô': 11, '‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°': 12,
    '‡∏°.‡∏Ñ.': 1, '‡∏Å.‡∏û.': 2, '‡∏°‡∏µ.‡∏Ñ.': 3, '‡πÄ‡∏°.‡∏¢.': 4,
    '‡∏û.‡∏Ñ.': 5, '‡∏°‡∏¥.‡∏¢.': 6, '‡∏Å.‡∏Ñ.': 7, '‡∏™.‡∏Ñ.': 8,
    '‡∏Å.‡∏¢.': 9, '‡∏ï.‡∏Ñ.': 10, '‡∏û.‡∏¢.': 11, '‡∏ò.‡∏Ñ.': 12
}

MONTH_NAMES = {
    1: '‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°', 2: '‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå', 3: '‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°', 4: '‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô',
    5: '‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°', 6: '‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô', 7: '‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°', 8: '‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°',
    9: '‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô', 10: '‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°', 11: '‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô', 12: '‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°'
}

EXCLUDE_COLUMNS = {"‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡πà"}


# ============================================================================
#                          DATABASE UTILITIES
# ============================================================================

def get_db_connection():
    """Get database connection"""
    try:
        conn = mysql.connector.connect(**DB_CONFIG)
        return conn
    except MySQLError as e:
        raise


def close_db_connection(conn):
    """Close database connection safely"""
    try:
        if conn and conn.is_connected():
            conn.close()
    except Exception as e:
        pass

# ============================================================================
#                          PASSWORD UTILITIES
# ============================================================================

def hash_password(password: str) -> str:
    """Hash password using bcrypt"""
    salt = bcrypt.gensalt()
    hashed = bcrypt.hashpw(password.encode('utf-8'), salt)
    return hashed.decode('utf-8')


def verify_password(password: str, hashed_password: str) -> bool:
    """Verify password against bcrypt hash"""
    try:
        return bcrypt.checkpw(
            password.encode('utf-8'), 
            hashed_password.encode('utf-8')
        )
    except Exception as e:
        return False


# ============================================================================
#                          DATA CLEANING UTILITIES
# ============================================================================

def clean_column_name(col: str) -> str:
    """Clean and standardize column names"""
    c = str(col).strip()
    if c.lower() in ['', 'nan', 'none', '#ref!']:
        c = "col_empty"
    
    safe = (c.replace(" ", "_")
             .replace("/", "_")
             .replace("-", "_")
             .replace(".", "_")
             .replace("(", "")
             .replace(")", "")
             .replace("%", "pct")
             .replace("#", "no"))
    return safe[:64]


def clean_value(val: Any) -> str:
    """Clean cell values"""
    if val is None or pd.isna(val):
        return ''
    s = str(val).strip()
    if s.lower() in ['nan', 'none', '#ref!', 'null']:
        return ''
    return s


def convert_to_decimal(value: Any) -> Optional[float]:
    """Convert value to decimal, removing commas and special characters"""
    if value is None or value == '' or pd.isna(value):
        return None
    
    s = str(value).strip()
    s = s.replace(',', '')
    s = re.sub(r'[^\d.-]', '', s)
    
    try:
        return float(s) if s else None
    except:
        return None


def convert_month_to_number(month_value: Any) -> Optional[int]:
    """Convert Thai month name or number to integer"""
    if month_value is None or month_value == '' or pd.isna(month_value):
        return None
    
    try:
        num = int(month_value)
        if 1 <= num <= 12:
            return num
    except:
        pass
    
    month_str = str(month_value).strip()
    return MONTH_MAP.get(month_str, None)


def clean_cid(value: Any) -> Optional[str]:
    """Clean and validate CID (13 digits)"""
    if value is None or value == '' or pd.isna(value):
        return None
    
    # ‡∏•‡∏ö‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
    cid = re.sub(r'\D', '', str(value))
    
    # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ 13 ‡∏´‡∏•‡∏±‡∏Å‡∏û‡∏≠‡∏î‡∏µ
    if len(cid) == 13:
        return cid
    
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà 13 ‡∏´‡∏•‡∏±‡∏Å ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô string ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤
    return cid if cid else None


def clean_year(value: Any) -> Optional[int]:
    """Clean and validate year - keep as Buddhist Era (‡∏û.‡∏®.)"""
    if value is None or value == '' or pd.isna(value):
        return None
    
    try:
        year = int(float(str(value).replace(',', '').strip()))
        
        # ‚úÖ ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏õ‡πá‡∏ô ‡∏û.‡∏®. ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤ (‡πÑ‡∏°‡πà‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô ‡∏Ñ.‡∏®.)
        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏µ ‡∏Ñ.‡∏®. (‡πÄ‡∏ä‡πà‡∏ô 2024) ‡πÉ‡∏´‡πâ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô ‡∏û.‡∏®.
        if year < 2500:
            year = year + 543
            
        return year
    except:
        return None


def clean_bank_account(value: Any) -> Optional[str]:
    """Clean bank account number"""
    if value is None or value == '' or pd.isna(value):
        return None
    
    try:
        # ‡∏•‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢ , - ‡πÅ‡∏•‡∏∞ space
        account = str(value).replace(',', '').replace('-', '').replace(' ', '').strip()
        # ‡∏•‡∏ö‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
        account = re.sub(r'\D', '', account)
        return account if account else None
    except:
        return None

# ============================================================================
#                          AUTHENTICATION ROUTES
# ============================================================================

@app.route("/api/register", methods=["POST"])
def register():
    """Register new user"""
    conn = None
    try:
        data = request.get_json()
        cid = data.get('cid', '').strip()
        password = data.get('password', '').strip()
        name = data.get('name', '').strip()
        status = data.get('status', '').strip()
        
        # Validation
        if not all([cid, password, name, status]):
            return jsonify({
                "status": "error",
                "message": "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô"
            }), 400
        
        # Hash password
        hashed_pwd = hash_password(password)
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Check if CID exists
        cursor.execute("SELECT cid FROM users WHERE cid = %s", (cid,))
        if cursor.fetchone():
            cursor.close()
            return jsonify({
                "status": "error",
                "message": "CID ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏•‡πâ‡∏ß"
            }), 400
        
        # Insert new user
        cursor.execute(
            """INSERT INTO users (cid, password, name, status)
               VALUES (%s, %s, %s, %s)""",
            (cid, hashed_pwd, name, status)
        )
        conn.commit()
        cursor.close()
        
        return jsonify({
            "status": "success",
            "message": "‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à"
        })
        
    except Exception as e:
        print(f"Register error: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "status": "error",
            "message": "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô"
        }), 500
    finally:
        close_db_connection(conn)


@app.route("/api/login", methods=["POST"])
def login():
    """User login - supports both plain text and bcrypt"""
    conn = None
    try:
        data = request.get_json()
        cid = data.get('cid', '').strip()
        password = data.get('password', '').strip()
        
        if not cid or not password:
            return jsonify({
                "status": "error",
                "message": "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å CID ‡πÅ‡∏•‡∏∞‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô"
            }), 400
        
        conn = get_db_connection()
        cursor = conn.cursor(dictionary=True)
        cursor.execute(
            "SELECT * FROM users WHERE cid = %s",
            (cid,)
        )
        user = cursor.fetchone()
        cursor.close()
        
        if not user:
            return jsonify({
                "status": "error",
                "message": "CID ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á"
            }), 401
        
        # Check if password is bcrypt hash or plain text
        stored_password = user['password']
        password_valid = False
        
        if stored_password.startswith('$2b$'):
            # Bcrypt hashed password
            password_valid = verify_password(password, stored_password)
        else:
            # Plain text password (temporary)
            password_valid = (password == stored_password)
        
        if not password_valid:
            return jsonify({
                "status": "error",
                "message": "CID ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á"
            }), 401
        
        return jsonify({
            "status": "success",
            "message": "‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à",
            "user": {
                "cid": user['cid'],
                "name": user['name'],
                "status": user.get('status', '')
            }
        })
            
    except Exception as e:
        print(f"Login error: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "status": "error",
            "message": "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö"
        }), 500
    finally:
        close_db_connection(conn)


@app.route("/api/hash-passwords", methods=["POST"])
def hash_existing_passwords():
    """Migration utility: Hash existing plain text passwords"""
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor(dictionary=True)
        cursor.execute("SELECT id, cid, password FROM users")
        users = cursor.fetchall()
        
        updated_count = 0
        skipped_count = 0
        
        for user in users:
            # Skip if already hashed
            if user['password'].startswith('$2b$'):
                skipped_count += 1
                continue
            
            hashed = hash_password(user['password'])
            cursor.execute(
                "UPDATE users SET password = %s WHERE id = %s",
                (hashed, user['id'])
            )
            updated_count += 1
        
        conn.commit()
        cursor.close()
        
        return jsonify({
            "status": "success",
            "message": "‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏´‡∏±‡∏™‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à",
            "updated": updated_count,
            "skipped": skipped_count
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            "status": "error",
            "message": str(e)
        }), 500
    finally:
        close_db_connection(conn)


# ============================================================================
#                          USER MANAGEMENT ROUTES
# ============================================================================

@app.route("/api/users", methods=["GET"])
def get_users():
    """Get all users (for admin)"""
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor(dictionary=True)
        cursor.execute(
            "SELECT cid, name, status, created_at FROM users ORDER BY created_at DESC"
        )
        users = cursor.fetchall()
        cursor.close()
        
        return jsonify({
            "status": "success",
            "users": users
        })
        
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": str(e)
        }), 500
    finally:
        close_db_connection(conn)


@app.route("/api/users/<cid>", methods=["DELETE"])
def delete_user(cid):
    """Delete user by CID"""
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("DELETE FROM users WHERE cid = %s", (cid,))
        
        if cursor.rowcount == 0:
            cursor.close()
            return jsonify({
                "status": "error",
                "message": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ"
            }), 404
        
        conn.commit()
        cursor.close()
        
        return jsonify({
            "status": "success",
            "message": "‡∏•‡∏ö‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à"
        })
        
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": str(e)
        }), 500
    finally:
        close_db_connection(conn)


# ============================================================================
#                          SALARY DATA ROUTES
# ============================================================================

@app.route("/api/salary-data", methods=["GET"])
def get_salary_data():
    """Get salary data with filters"""
    conn = None
    try:
        cid = request.args.get('cid', '')
        name = request.args.get('name', '')
        month = request.args.get('month', '')
        year = request.args.get('year', '')
        employee = request.args.get('employee', '')
        
        # Convert month
        month_number = None
        if month:
            month_number = convert_month_to_number(month)
        
        conn = get_db_connection()
        cursor = conn.cursor(dictionary=True)
        
        query = "SELECT * FROM salary_data WHERE 1=1"
        params = []
        
        if cid:
            query += " AND cid LIKE %s"
            params.append(f"%{cid}%")
        
        if name:
            query += " AND name LIKE %s"
            params.append(f"%{name}%")
            
        if month_number is not None:
            query += " AND month = %s"
            params.append(month_number)
            
        if year:
            query += " AND year = %s"
            params.append(year)
            
        if employee:
            query += " AND employee = %s"
            params.append(employee)
        
        query += """
            ORDER BY 
                CASE 
                    WHEN employee = '‡∏Ç‡πâ‡∏≤‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£' THEN 0 
                    WHEN employee = '‡∏•‡∏π‡∏Å‡∏à‡πâ‡∏≤‡∏á‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô' THEN 1 
                    ELSE 2 
                END,
                id ASC
        """
        
        cursor.execute(query, params)
        results = cursor.fetchall()
        
        # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á BIGINT ‡πÄ‡∏õ‡πá‡∏ô string ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Frontend
        for row in results:
            if row.get('cid'):
                row['cid'] = str(row['cid'])
            if row.get('bank_account'):
                row['bank_account'] = str(row['bank_account'])
        
        cursor.close()
        
        return jsonify({
            "status": "success",
            "data": results,
            "count": len(results)
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            "status": "error",
            "message": str(e)
        }), 500
    finally:
        close_db_connection(conn)


@app.route("/api/available-filters", methods=["GET"])
def get_available_filters():
    """Get available months and years for filtering"""
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Get months
        cursor.execute(
            "SELECT DISTINCT month FROM salary_data WHERE month IS NOT NULL ORDER BY month"
        )
        months_data = cursor.fetchall()
        
        available_months = []
        for (month_num,) in months_data:
            if month_num in MONTH_NAMES:
                available_months.append({
                    'value': MONTH_NAMES[month_num],
                    'label': MONTH_NAMES[month_num],
                    'number': month_num
                })
        
        # Get years
        cursor.execute(
            "SELECT DISTINCT year FROM salary_data WHERE year IS NOT NULL ORDER BY year DESC"
        )
        years_data = cursor.fetchall()
        available_years = [str(year[0]) for year in years_data]
        cursor.close()
        
        return jsonify({
            "status": "success",
            "months": available_months,
            "years": available_years
        })
        
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": str(e)
        }), 500
    finally:
        close_db_connection(conn)


@app.route("/api/reset-table", methods=["POST"])
def reset_table():
    """Reset salary_data table"""
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("TRUNCATE TABLE salary_data")
        conn.commit()
        cursor.close()
        
        return jsonify({
            "status": "success",
            "message": "‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ reset ID ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß"
        })
        
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": str(e)
        }), 500
    finally:
        close_db_connection(conn)


# ============================================================================
#                          FILE UPLOAD & PROCESSING
# ============================================================================

def save_to_mysql(df: pd.DataFrame) -> int:
    """Save DataFrame to MySQL"""
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        df.columns = [clean_column_name(c) for c in df.columns]
        
        # Create table if not exists
        cursor.execute("SHOW TABLES LIKE 'salary_data'")
        if not cursor.fetchone():
            col_defs = []
            for c in df.columns:
                clean_col = clean_column_name(c)
                
                if clean_col in ['name', 'employee', 'employee_type']:
                    col_defs.append(f"`{clean_col}` VARCHAR(255)")
                elif clean_col in ['cid', 'bank_account']:
                    col_defs.append(f"`{clean_col}` VARCHAR(20)")  # ‚úÖ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô VARCHAR
                elif clean_col == 'year':
                    col_defs.append(f"`{clean_col}` INT")
                elif clean_col == 'month':
                    col_defs.append(f"`{clean_col}` TINYINT")
                elif clean_col in NUMERIC_COLUMNS:
                    col_defs.append(f"`{clean_col}` DECIMAL(15,2)")
                else:
                    col_defs.append(f"`{clean_col}` TEXT")
            
            cols_sql = ", ".join(col_defs)
            cursor.execute(f"""
                CREATE TABLE salary_data (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    {cols_sql},
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
        
        saved = updated = failed = 0
        
        for idx, row in df.iterrows():
            try:
                processed_row = {}
                
                for col in df.columns:
                    clean_col = clean_column_name(col)
                    value = row[col]
                    
                    if clean_col == 'cid':
                        processed_row[clean_col] = clean_cid(value)
                    elif clean_col == 'year':
                        processed_row[clean_col] = clean_year(value)
                    elif clean_col == 'month':
                        processed_row[clean_col] = convert_month_to_number(value)
                    elif clean_col == 'bank_account':
                        processed_row[clean_col] = clean_bank_account(value)
                    elif clean_col in NUMERIC_COLUMNS:
                        processed_row[clean_col] = convert_to_decimal(value)
                    else:
                        v = clean_value(value)
                        processed_row[clean_col] = v if v != '' else None
                
                # ‡πÄ‡∏ä‡πá‡∏Ñ duplicate
                cid = processed_row.get('cid')
                month = processed_row.get('month')
                year = processed_row.get('year')
                
                exists = None
                
                if cid and month is not None and year is not None:
                    cursor.execute(
                        "SELECT id FROM salary_data WHERE cid = %s AND month = %s AND year = %s",
                        (cid, month, year)
                    )
                    exists = cursor.fetchone()
                
                columns = [clean_column_name(c) for c in df.columns]
                values = [processed_row.get(clean_column_name(c)) for c in df.columns]
                
                if exists:
                    set_clause = ", ".join([f"`{c}`=%s" for c in columns])
                    cursor.execute(
                        f"UPDATE salary_data SET {set_clause} WHERE id=%s",
                        values + [exists[0]]
                    )
                    updated += 1
                else:
                    cols_str = ", ".join([f"`{c}`" for c in columns])
                    placeholders = ", ".join(["%s"] * len(columns))
                    cursor.execute(
                        f"INSERT INTO salary_data ({cols_str}) VALUES ({placeholders})",
                        values
                    )
                    saved += 1
                    
            except Exception as e:
                print(f"Error processing row {idx}: {e}")
                import traceback
                traceback.print_exc()
                failed += 1
                continue

        conn.commit()
        cursor.close()

        print(f"‚úÖ Saved: {saved}, Updated: {updated}, Failed: {failed}")
        return saved + updated
        
    finally:
        close_db_connection(conn)


@app.route("/upload", methods=["POST"])
def upload_api():
    """Upload and process Excel file"""
    if 'file' not in request.files:
        return jsonify({"error": "No file"}), 400
    
    if 'month' not in request.form or 'year' not in request.form:
        return jsonify({"error": "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏µ"}), 400
    
    file = request.files['file']
    selected_month = request.form['month']
    selected_year = request.form['year']
    
    selected_month_num = convert_month_to_number(selected_month)
    if selected_month_num is None:
        return jsonify({"error": "‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á"}), 400
    
    path = os.path.join(UPLOAD_FOLDER, file.filename)
    file.save(path)
    
    try:
        wb = openpyxl.load_workbook(path, data_only=True)
        dfs = []
        skipped = []
        
        for sheet_name in wb.sheetnames:
            sheet = wb[sheet_name]
            rows = list(sheet.iter_rows(values_only=True))
            
            if not rows:
                skipped.append(sheet_name)
                continue
            
            # Process header
            raw_header = []
            for h in rows[0]:
                if h is None or str(h).strip().lower() in ["", "nan", "none", "#ref!"]:
                    raw_header.append("col_empty")
                else:
                    raw_header.append(str(h).strip())
            
            data_rows = rows[1:]
            
            # Remove footer rows
            cut = None
            for i, r in enumerate(data_rows):
                if any(isinstance(c, str) and "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°" in c for c in r if c):
                    cut = i
                    break
            if cut is not None:
                data_rows = data_rows[:cut]
            
            # Filter empty rows
            filtered = []
            for r in data_rows:
                if r and not all(c in [None, "", " "] for c in r):
                    filtered.append(r)
            
            if not filtered:
                skipped.append(sheet_name)
                continue
            
            # Create DataFrame
            max_cols = max(len(raw_header), max(len(r) for r in filtered))
            header = raw_header + [f"col_empty_{i}" for i in range(len(raw_header), max_cols)]
            
            fixed_rows = [list(r) + ['']*(max_cols - len(r)) for r in filtered]
            df = pd.DataFrame(fixed_rows, columns=header)
            
            # Remove excluded columns
            df = df[[c for c in df.columns if c not in EXCLUDE_COLUMNS]]
            
            # ‚úÖ Map column names ‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô
            mapped_cols = []
            for c in df.columns:
                key = str(c).strip()
                if key.lower() in ["", "nan", "none"]:
                    key = "col_empty"
                mapped_cols.append(COLUMN_MAP.get(key, key))
            
            df.columns = mapped_cols
            
            # üîß ‡∏£‡∏ß‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô (‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡πÄ‡∏õ‡πá‡∏ô _1, _2)
            duplicate_cols = {}
            for col in df.columns:
                if col not in duplicate_cols:
                    duplicate_cols[col] = []
                duplicate_cols[col].append(col)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡πÉ‡∏´‡∏°‡πà‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°‡∏Ñ‡πà‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ã‡πâ‡∏≥
            merged_df = pd.DataFrame()
            processed_cols = set()
            
            for col in df.columns:
                if col in processed_cols:
                    continue
                    
                # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
                same_name_cols = [c for i, c in enumerate(df.columns) if df.columns[i] == col]
                
                if len(same_name_cols) > 1:
                    # ‚úÖ ‡∏£‡∏ß‡∏°‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà null/empty)
                    combined_values = []
                    for idx in range(len(df)):
                        values = []
                        for sc in same_name_cols:
                            val = df.iloc[idx][sc]
                            if val not in [None, '', ' '] and not pd.isna(val):
                                # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç ‡πÉ‡∏´‡πâ‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô
                                if col in NUMERIC_COLUMNS:
                                    try:
                                        values.append(convert_to_decimal(val) or 0)
                                    except:
                                        pass
                                else:
                                    values.append(val)
                        
                        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö numeric columns ‡πÉ‡∏´‡πâ‡∏£‡∏ß‡∏°‡∏Ñ‡πà‡∏≤
                        if col in NUMERIC_COLUMNS and values:
                            combined_values.append(sum(values))
                        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö text columns ‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏≤‡∏Ñ‡πà‡∏≤‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á
                        elif values:
                            combined_values.append(values[0])
                        else:
                            combined_values.append(None)
                    
                    merged_df[col] = combined_values
                else:
                    merged_df[col] = df[col]
                
                processed_cols.add(col)
            
            df = merged_df
            
            # Clean column names
            df.columns = [clean_column_name(c) for c in df.columns]
            
            # Remove unwanted columns
            columns_to_drop = ['order_no', 'row_no']
            for col in columns_to_drop:
                if col in df.columns:
                    df = df.drop(columns=[col])
            
            # Add default CID if missing
            if 'cid' not in df.columns:
                df['cid'] = [f"{sheet_name}_{i}" for i in range(len(df))]
            
            # Add metadata
            df['employee'] = sheet_name
            df['month'] = selected_month_num
            df['year'] = selected_year
            
            dfs.append(df)
        
        if not dfs:
            return jsonify({
                "error": "No usable sheets",
                "skipped": skipped
            }), 400
        
        # Combine all sheets
        final_df = pd.concat(dfs, ignore_index=True)
        
        # Save to database
        saved = save_to_mysql(final_df)
        
        return jsonify({
            "status": "success",
            "processed_sheets": [d['employee'].iloc[0] for d in dfs],
            "skipped_sheets": skipped,
            "rows": len(final_df),
            "saved": saved,
            "selected_month": selected_month_num,
            "selected_year": selected_year
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 400
        
    finally:
        try:
            os.remove(path)
        except:
            pass

# ============================================================================
#                          MAIN
# ============================================================================

if __name__ == '__main__':
    app.run(debug=True, host="127.0.0.1", port=5000)